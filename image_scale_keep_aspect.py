# å›¾åƒç­‰æ¯”ç¼©æ”¾å™¨ä¿®æ”¹
import torch
import numpy as np
from PIL import Image
import comfy.utils

class å›¾åƒç­‰æ¯”ç¼©æ”¾å™¨:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "æ’å€¼": (["Nearest-æœ€è¿‘é‚»æ’å€¼-æœ€å¿«", "BiLinear-åŒçº¿æ€§æ’å€¼-è¾ƒå¿«", "BiCubic-åŒä¸‰æ¬¡æ’å€¼-ä¸­ç­‰", "Area-åŒºåŸŸæ’å€¼-è¾ƒæ…¢", "Lanczos-é‚»åŸŸæ’å€¼-æœ€æ…¢"], {"default": "BiCubic-åŒä¸‰æ¬¡æ’å€¼-ä¸­ç­‰"}),
                "å®½åº¦": ("INT", {"default": 0, "min": 0}),
                "é«˜åº¦": ("INT", {"default": 0, "min": 0}),
                "å›¾åƒ": ("IMAGE",),
            },
            "optional": {
                "é®ç½©": ("MASK",), 
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("å›¾åƒ", "é®ç½©")
    FUNCTION = "resize_image"
    CATEGORY = "â›°ï¸CRå·¥å…·"

    def resize_image(self, æ’å€¼, å®½åº¦, é«˜åº¦, å›¾åƒ, é®ç½©=None):
        if å®½åº¦ == 0 and é«˜åº¦ == 0:
            return (å›¾åƒ, é®ç½©)
            
        # æ˜ å°„æ’å€¼æ–¹æ³•åˆ°PILçš„å¯¹åº”å€¼
        interpolation_map = {
            "Nearest-æœ€è¿‘é‚»æ’å€¼-æœ€å¿«": Image.NEAREST,
            "BiLinear-åŒçº¿æ€§æ’å€¼--è¾ƒå¿«": Image.BILINEAR,
            "BiCubic-åŒä¸‰æ¬¡æ’å€¼-ä¸­ç­‰": Image.BICUBIC,
            "Area-åŒºåŸŸæ’å€¼-è¾ƒæ…¢": Image.BOX,
            "Lanczos-é‚»åŸŸæ’å€¼-æœ€æ…¢": Image.LANCZOS
        }
        interpolation = interpolation_map.get(æ’å€¼, Image.BICUBIC)

        orig_h = å›¾åƒ.shape[1]
        orig_w = å›¾åƒ.shape[2]

        if å®½åº¦ == 0:
            scale = é«˜åº¦ / orig_h
            new_w = int(orig_w * scale)
            new_h = é«˜åº¦
        elif é«˜åº¦ == 0:
            scale = å®½åº¦ / orig_w
            new_w = å®½åº¦
            new_h = int(orig_h * scale)
        else:
            scale_w = å®½åº¦ / orig_w
            scale_h = é«˜åº¦ / orig_h
            scale = min(scale_w, scale_h)
            new_w = int(orig_w * scale)
            new_h = int(orig_h * scale)

        if new_w <= 0 or new_h <= 0:
            raise ValueError("è°ƒæ•´åçš„å®½åº¦å’Œé«˜åº¦å¿…é¡»å¤§äº0")

        pil_images = []
        for img in å›¾åƒ:
            img_np = img.cpu().numpy()
            if img_np.dtype != np.uint8:
                img_np = (img_np * 255).astype(np.uint8)
            pil_img = Image.fromarray(img_np, mode='RGB')
            pil_resized = pil_img.resize((new_w, new_h), interpolation)
            pil_images.append(pil_resized)

        output_images = []
        for pil_img in pil_images:
            img_array = np.array(pil_img).astype(np.float32) / 255.0
            output_images.append(torch.from_numpy(img_array))

        if output_images:
            final_image = torch.stack(output_images, dim=0)
        else:
            final_image = å›¾åƒ 

        final_mask = é®ç½©
        if é®ç½© is not None:
            try:
                mask_pils = []
                for m in é®ç½©:
                    m_np = m.cpu().numpy()
                    if m_np.dtype != np.uint8:
                        m_np = (m_np * 255).astype(np.uint8)
                    mask_pil = Image.fromarray(m_np.squeeze(), mode='L') 
                    mask_resized = mask_pil.resize((new_w, new_h), Image.NEAREST)
                    mask_pils.append(mask_resized)

                mask_arrays = []
                for mask_pil in mask_pils:
                    mask_array = np.array(mask_pil).astype(np.float32) / 255.0
                    mask_arrays.append(torch.from_numpy(mask_array).unsqueeze(0)) 

                if mask_arrays:
                    final_mask = torch.cat(mask_arrays, dim=0)
                else:
                    final_mask = é®ç½©
            except Exception as e:
                print(f"è°ƒæ•´é®ç½©å°ºå¯¸æ—¶å‡ºé”™: {e}")
                pass

        return (final_image, final_mask)

NODE_CLASS_MAPPINGS = {
    "ğŸ–¼ï¸å›¾åƒç­‰æ¯”ç¼©æ”¾å™¨": å›¾åƒç­‰æ¯”ç¼©æ”¾å™¨,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ğŸ–¼ï¸å›¾åƒç­‰æ¯”ç¼©æ”¾å™¨": "å›¾åƒç­‰æ¯”ç¼©æ”¾å™¨"
}